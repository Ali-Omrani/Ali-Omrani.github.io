pub_date	title	venue	excerpt	citation	url_slug	paper_url
2022-03-01	Introducing the Gab Hate Corpus: defining and applying hate-based rhetoric to social media posts at scale	Language Resources and Evaluation	The Gab Hate Corpus (GHC) contains 27,665 posts from gab.com, annotated for "hate-based rhetoric" by three or more annotators. It includes hierarchical labels for dehumanizing and violent speech, targeted groups, and rhetorical framing. The GHC enhances existing hate speech datasets with a large, representative collection of richly annotated social media posts	Kennedy, Brendan, et al. "Introducing the Gab Hate Corpus: defining and applying hate-based rhetoric to social media posts at scale." Language Resources and Evaluation (2022): 1-30.	paper-title-number-1	https://par.nsf.gov/servlets/purl/10322251
2021-07-01	Moral concerns are differentially observable in language	Cognition 	We examined the connection between language usage and moral concerns. We collected a large dataset of Facebook status updates from English-speaking participants, along with their responses on the Moral Foundations Questionnaire. Our findings indicate that individuals' moral concerns can be identified through their language usage, although the strength of this relationship varies across different moral dimensions. 	Kennedy, Brendan, et al. "Moral concerns are differentially observable in language." Cognition 212 (2021): 104696.	paper-title-number-2	https://par.nsf.gov/servlets/purl/10220769
2021-08-03	Improving counterfactual generation for fair hate speech detection	ACL 2021	Bias mitigation approaches reduce models' dependence on sensitive features of data, such as social group tokens (SGTs), resulting in equal predictions across the sensitive features. In hate speech detection, however, equalizing model predictions may ignore important differences among targeted social groups, as hate speech can contain stereotypical language specific to each SGT. Here, to take the specific language about each SGT into account, we rely on counterfactual fairness and equalize predictions among counterfactuals, generated by changing the SGTs. Our method evaluates the similarity in sentence likelihoods (via pre-trained language models) among counterfactuals, to treat SGTs equally only within interchangeable contexts. By applying logit pairing to equalize outcomes on the restricted set of counterfactuals for each instance, we improve fairness metrics while preserving model performance on hate speech detection.	Davani, Aida Mostafazadeh, et al. "Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)." Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021). 2021.	paper-title-number-3	https://aclanthology.org/2021.woah-1.10/
2023-07-01	Social-Group-Agnostic Bias Mitigation via the Stereotype Content Model	ACL 2023	Existing methods typically rely on word pairs specific to certain social groups, limiting their effectiveness to one aspect of social identity. This approach becomes impractical and costly when addressing bias in lesser-known or unmarked social groups. Instead, we proposed leveraging the Stereotype Content Model (SCM), a framework from social psychology. The SCM categorizes stereotypes along two dimensions: warmth and competence. By adopting this social-group-agnostic perspective, we demonstrated comparable performance to group-specific debiasing methods while offering theoretical and practical advantages over existing techniques.	Ali Omrani, Alireza Salkhordeh Ziabari, Charles Yu, Preni Golazizian, Brendan Kennedy, Mohammad Atari, Heng Ji, and Morteza Dehghani. 2023. Social-Group-Agnostic Bias Mitigation via the Stereotype Content Model. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4123â€“4139, Toronto, Canada. Association for Computational Linguistics.    paper-title-number-3	https://aclanthology.org/2023.acl-long.227.pdf