pub_date	title	venue	excerpt	citation	url_slug	paper_url
2022-03-01	Introducing the Gab Hate Corpus: defining and applying hate-based rhetoric to social media posts at scale	Language Resources and Evaluation	The Gab Hate Corpus (GHC) contains 27,665 posts from gab.com, annotated for "hate-based rhetoric" by three or more annotators. It includes hierarchical labels for dehumanizing and violent speech, targeted groups, and rhetorical framing. The GHC enhances existing hate speech datasets with a large, representative collection of richly annotated social media posts	Kennedy, Brendan, et al. "Introducing the Gab Hate Corpus: defining and applying hate-based rhetoric to social media posts at scale." Language Resources and Evaluation (2022): 1-30.	GHC	https://par.nsf.gov/servlets/purl/10322251
2021-07-01	Moral concerns are differentially observable in language	Cognition 	We examined the connection between language usage and moral concerns. We collected a large dataset of Facebook status updates from English-speaking participants, along with their responses on the Moral Foundations Questionnaire. Our findings indicate that individuals' moral concerns can be identified through their language usage, although the strength of this relationship varies across different moral dimensions. 	Kennedy, Brendan, et al. "Moral concerns are differentially observable in language." Cognition 212 (2021): 104696.	FB-cognition	https://par.nsf.gov/servlets/purl/10220769
2021-08-03	Improving counterfactual generation for fair hate speech detection	ACL 2021	Bias mitigation approaches reduce models' dependence on sensitive features of data, such as social group tokens (SGTs), resulting in equal predictions across the sensitive features. In hate speech detection, however, equalizing model predictions may ignore important differences among targeted social groups, as hate speech can contain stereotypical language specific to each SGT. Here, to take the specific language about each SGT into account, we rely on counterfactual fairness and equalize predictions among counterfactuals, generated by changing the SGTs. Our method evaluates the similarity in sentence likelihoods (via pre-trained language models) among counterfactuals, to treat SGTs equally only within interchangeable contexts. By applying logit pairing to equalize outcomes on the restricted set of counterfactuals for each instance, we improve fairness metrics while preserving model performance on hate speech detection.	Davani, Aida Mostafazadeh, et al. "Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)." Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021). 2021.	Counterfactual	https://aclanthology.org/2021.woah-1.10/
2023-07-01	Social-Group-Agnostic Bias Mitigation via the Stereotype Content Model	ACL 2023	Existing methods typically rely on word pairs specific to certain social groups, limiting their effectiveness to one aspect of social identity. This approach becomes impractical and costly when addressing bias in lesser-known or unmarked social groups. Instead, we proposed leveraging the Stereotype Content Model (SCM), a framework from social psychology. The SCM categorizes stereotypes along two dimensions: warmth and competence. By adopting this social-group-agnostic perspective, we demonstrated comparable performance to group-specific debiasing methods while offering theoretical and practical advantages over existing techniques.	Ali Omrani, Alireza Salkhordeh Ziabari, Charles Yu, Preni Golazizian, Brendan Kennedy, Mohammad Atari, Heng Ji, and Morteza Dehghani. 2023. Social-Group-Agnostic Bias Mitigation via the Stereotype Content Model. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4123–4139, Toronto, Canada. Association for Computational Linguistics.	SCMD	https://aclanthology.org/2023.acl-long.227.pdf
2023/4/12	The paucity of morality in everyday talk	Scientific Reports	Given its centrality in scholarly and popular discourse, morality should be expected to figure prominently in everyday talk. We test this expectation by examining the frequency of moral content in three contexts, using three methods: (a) Participants’ subjective frequency estimates (N = 581); (b) Human content analysis of unobtrusively recorded in-person interactions (N = 542 participants; n = 50,961 observations); and (c) Computational content analysis of Facebook posts (N = 3822 participants; n = 111,886 observations). In their self-reports, participants estimated that 21.5% of their interactions touched on morality (Study 1), but objectively, only 4.7% of recorded conversational samples (Study 2) and 2.2% of Facebook posts (Study 3) contained moral content. Collectively, these findings suggest that morality may be far less prominent in everyday life than scholarly and popular discourse, and laypeople ...	Atari, Mohammad, Matthias R. Mehl, Jesse Graham, John M. Doris, Norbert Schwarz, Aida Mostafazadeh Davani, Ali Omrani et al. "The paucity of morality in everyday talk." Scientific Reports 13, no. 1 (2023): 5967.	Paucity	https://www.nature.com/articles/s41598-023-32711-4